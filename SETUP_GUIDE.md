# Arogya-Swarm - Full Stack Setup Guide

## Project Structure

This project now has the complete backend infrastructure from MumbaiHacks-Tensors integrated with the Arogya-Swarm frontend.

```
Arogya-Swarm-Mumbai-Hacks-/
â”œâ”€â”€ frontend/             # React Frontend Application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/  # React UI components
â”‚   â”‚   â”œâ”€â”€ hooks/       # React hooks for API/WebSocket
â”‚   â”‚   â”œâ”€â”€ lib/         # API client and WebSocket manager
â”‚   â”‚   â”œâ”€â”€ App.tsx      # Main app component
â”‚   â”‚   â”œâ”€â”€ main.tsx     # Entry point
â”‚   â”‚   â””â”€â”€ index.css    # Global styles
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ vite.config.ts
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ backend/              # Backend API and Agent System
â”‚   â”œâ”€â”€ agents/          # Multi-agent orchestration
â”‚   â”œâ”€â”€ api/             # FastAPI routes and WebSocket
â”‚   â”œâ”€â”€ core/            # Config, database, redis
â”‚   â”œâ”€â”€ models/          # SQLAlchemy models
â”‚   â”œâ”€â”€ services/        # External services (AQI, weather, SMS)
â”‚   â”œâ”€â”€ simulation/      # Crisis simulation tools
â”‚   â””â”€â”€ main.py          # FastAPI entry point
â”œâ”€â”€ database/            # PostgreSQL schema and migrations
â”œâ”€â”€ docker-compose.yml   # PostgreSQL + Redis setup
â””â”€â”€ .env.local           # Environment variables
```

## Prerequisites

1. **Node.js** (v18+) - For frontend
2. **Python** (3.10+) - For backend
3. **Docker Desktop** - For PostgreSQL and Redis
4. **API Keys**:
   - Google Gemini API key (for AI agents)
   - OpenWeatherMap API key (optional)
   - SAFAR Air API key (optional)

## Setup Instructions

### 1. Backend Setup

#### Install Python Dependencies

```powershell
cd backend
python -m venv venv
.\venv\Scripts\activate
pip install -r requirements.txt
```

#### Configure Environment Variables

Create `backend\.env`:

```env
# Database
DATABASE_URL=postgresql://arogya:swarm2024@localhost:5432/arogya_swarm

# Redis
REDIS_URL=redis://localhost:6379/0

# Google Gemini API
GOOGLE_API_KEY=your_gemini_api_key_here

# External Services (Optional)
OPENWEATHERMAP_API_KEY=your_weather_api_key
SAFAR_AIR_API_KEY=your_air_quality_api_key

# Twilio SMS (Optional)
TWILIO_ACCOUNT_SID=your_twilio_sid
TWILIO_AUTH_TOKEN=your_twilio_token
TWILIO_PHONE_NUMBER=your_twilio_phone

# Application Settings
FRONTEND_URL=http://localhost:3000
HOSPITAL_CITY=Mumbai
```

#### Start Database Services

```powershell
# From project root
docker-compose up -d
```

This starts:
- PostgreSQL on port 5432
- Redis on port 6379

#### Initialize Database

```powershell
cd backend
python -c "from core.database import engine, Base; Base.metadata.create_all(bind=engine); print('âœ“ Database initialized')"
```

Optional: Load seed data
```powershell
# If you have psql installed
psql -U arogya -d arogya_swarm -f ..\database\seed_data.sql
```

#### Run Backend Server

```powershell
cd backend
.\venv\Scripts\activate
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

Backend will be available at: http://localhost:8000
API Docs: http://localhost:8000/docs

### 2. Frontend Setup

#### Install Dependencies

```powershell
cd frontend
npm install
```

#### Configure Environment

Your `frontend\.env.local` is already configured:

```env
# API Configuration
VITE_API_URL=http://localhost:8000
VITE_WS_URL=ws://localhost:8000/ws

# Gemini API Key
GEMINI_API_KEY=AIzaSyAWPOmNrxeSxFQhqqNENZQFKT1ix5MUDrk
```

#### Run Frontend

```powershell
cd frontend
npm run dev
```

Frontend will be available at: http://localhost:5173

## Testing the Integration

### 1. Check Backend Health

Open http://localhost:8000/health - Should return `{"status": "healthy"}`

### 2. Check WebSocket Connection

Open the frontend at http://localhost:5173, click "Get Started" to enter dashboard.

Look for the connection status indicator in the top right:
- ðŸŸ¢ "Connected" = WebSocket is active
- ðŸ”´ "Disconnected" = WebSocket connection failed

### 3. Test Agent System

1. In the dashboard, change the scenario (Normal â†’ Pollution â†’ Festival â†’ Outbreak)
2. This triggers a backend crisis simulation
3. Watch the "Agent Activity Feed" panel for real-time agent messages
4. The "Decisions" tab should populate with AI-generated recommendations

### 4. Verify Data Flow

- **Resources Tab**: Shows real-time bed, staff, and inventory data from database
- **Overview Tab**: Displays surge predictions from the AI agents
- **Decisions Tab**: Lists recommendations generated by action agents
- **Advisory Tab**: Shows patient advisories and system actions

## Key Features

### Real-Time Updates
- WebSocket connection provides live updates from agent system
- Agents run every 5 minutes in background (configurable in `main.py`)
- Dashboard updates automatically when new recommendations arrive

### Multi-Agent System
- **Sentinel Agent**: Detects surge patterns, analyzes external data
- **Orchestrator Agent**: Coordinates between all agents
- **Logistics Agent**: Manages supply chain and inventory
- **Action Agents**: Generate specific recommendations for staff, patients, supplies

### Crisis Simulation
- Switch scenarios to simulate different crisis types
- Backend adjusts AQI, weather, and event data
- Agents respond with context-appropriate recommendations

## Troubleshooting

### Backend won't start
- Check if PostgreSQL and Redis are running: `docker-compose ps`
- Verify `.env` file has correct DATABASE_URL
- Check Python version: `python --version` (should be 3.10+)

### Frontend can't connect
- Verify backend is running on port 8000
- Check browser console for CORS errors
- Ensure `.env.local` has correct VITE_API_URL and VITE_WS_URL

### No agent messages appearing
- Check backend logs for errors in agent execution
- Verify GOOGLE_API_KEY is set in `backend\.env`
- Agents run every 5 minutes; you can adjust in `main.py` (search for `await asyncio.sleep(300)`)

### Database connection errors
- Ensure Docker containers are running: `docker-compose ps`
- Check database credentials match in docker-compose.yml and .env
- Try recreating containers: `docker-compose down -v && docker-compose up -d`

## Development Workflow

### Making Frontend Changes
1. Edit components in `components/` directory
2. UI updates automatically with Vite hot reload
3. Use existing hooks in `hooks/` to access backend data

### Making Backend Changes
1. Edit agents in `backend/agents/`
2. Modify API routes in `backend/api/routes.py`
3. Backend auto-reloads with `--reload` flag

### Adding New API Endpoints
1. Add route in `backend/api/routes.py`
2. Add corresponding function in `lib/api.ts`
3. Use the function in components or hooks

## Production Deployment

For production:
1. Set `FRONTEND_URL` in backend .env to your production domain
2. Build frontend: `npm run build`
3. Serve frontend build with a web server (nginx, etc.)
4. Run backend with gunicorn: `gunicorn -w 4 -k uvicorn.workers.UvicornWorker main:app`
5. Set up proper SSL certificates
6. Use production-grade PostgreSQL and Redis instances

## Next Steps

- [ ] Customize agent prompts in `backend/agents/`
- [ ] Add more crisis scenarios in `backend/simulation/scenarios.py`
- [ ] Implement user authentication
- [ ] Add data visualization for historical trends
- [ ] Set up monitoring and alerting
- [ ] Deploy to cloud platform

## Support

For issues or questions:
1. Check backend logs: Look at uvicorn console output
2. Check frontend console: Open browser DevTools
3. Review API docs: http://localhost:8000/docs
4. Test API endpoints directly with the interactive docs
